# â™»ï¸ AI-Powered Waste Classification using CNN & Grad-CAM

This project classifies waste images into **Organic** or **Recyclable** categories using a **Convolutional Neural Network (CNN)** built with **TensorFlow/Keras** and fine-tuned with **MobileNetV2** for high accuracy.  
It includes an interactive **Streamlit web app** that lets users upload images, view predictions, and see **Grad-CAM visualizations** highlighting the regions that influenced the modelâ€™s decision â€” making the AI explainable and trustworthy.

---

## ğŸš€ Features

- ğŸ§  **Deep Learning Model:** MobileNetV2 transfer learning + fine-tuning (~92% test accuracy)  
- ğŸ” **Explainable AI:** Grad-CAM overlay shows what part of the image the model focused on  
- ğŸŒ **Streamlit Web App:** Simple UI for real-time testing and predictions  
- ğŸ“Š **Jupyter Notebook:** Train, evaluate, and visualize model performance  
- ğŸ’¾ **Modular Codebase:** Clean `src/` structure with reusable components  
- ğŸ§© **Sustainability Focus:** Supports smart waste segregation and eco-friendly solutions  

---

## ğŸ“‚ Project Structure

sustainability_cnn/
â”œâ”€â”€ data/ # dataset (not included)
â”œâ”€â”€ models/ # trained models (.h5/.keras)
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ train_model.ipynb # training notebook
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ app_streamlit.py # Streamlit web app
â”‚ â”œâ”€â”€ data_loader.py # data loading & preprocessing
â”‚ â”œâ”€â”€ gradcam.py # Grad-CAM visualization
â”‚ â”œâ”€â”€ model_builder.py # CNN / MobileNetV2 model
â”‚ â”œâ”€â”€ predict.py # CLI prediction script
â”‚ â””â”€â”€ train.py # training script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Procfile
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md



---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/sustainability_cnn.git
cd sustainability_cnn
2ï¸âƒ£ Create and Activate Virtual Environment

python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt
4ï¸âƒ£ Run the Web App

streamlit run src/app_streamlit.py
Visit http://localhost:8501 in your browser to use the app.

ğŸ§  Model Details
Architecture: MobileNetV2 (pretrained on ImageNet)

Fine-tuning: Last 50 layers unfrozen for domain adaptation

Optimizer: Adam (LR: 1e-4 â†’ 1e-5 during fine-tune)

Loss: Binary Crossentropy

Accuracy: ~92% on test set

### ğŸ§  Model Information
The model file used in this deployment is:
`models/waste_classifier_finetuned.h5` (~26 MB)

This is the **final fine-tuned MobileNetV2 model** trained for the highest accuracy (~92%).  
It is included in this repository for easy testing and deployment.


Explainability: Grad-CAM visualization for model transparency

ğŸ“¸ How It Works
User uploads a waste image (e.g., banana peel or plastic bottle).

The model processes the image (resized â†’ normalized â†’ prediction).

The output shows:

Predicted class: Organic / Recyclable

Confidence score (0â€“1)

Grad-CAM heatmap overlay to explain the decision

Example:

Input Image	                 Grad-CAM Overlay	                    Prediction
ğŸŒ Banana Peel	        ğŸ”¥ Focused on organic texture	            ğŸŒ± Organic (0.08)
ğŸ§´ Plastic Bottle	    ğŸ”¥ Focused on bottle region	                 â™»ï¸ Recyclable (0.93)

ğŸŒ Deployment
ğŸŸ¢ Streamlit Community Cloud (Recommended)
Push your repo to GitHub.

Go to https://share.streamlit.io.

Click â€œNew Appâ€ â†’ select repo â†’ path: src/app_streamlit.py.

Click Deploy â€” get a free public URL accessible from any device.

ğŸ³ Docker Deployment

docker build -t waste-classifier .
docker run -p 8501:8501 waste-classifier
Open http://localhost:8501 to access your app.

ğŸ“± Mobile Access (via ngrok)

streamlit run src/app_streamlit.py
ngrok http 8501
Use the https:// ngrok URL on your phone.

ğŸ§© Model File Management
The trained model (waste_classifier_finetuned.h5) is ignored by Git by default.

Use Git LFS or cloud storage (e.g., Google Drive, S3) for large files.

You can also convert to .keras or .tflite for lightweight deployment.

ğŸ§ª CLI Prediction
You can also classify a single image from the command line:


python src/predict.py --image path/to/image.jpg
ğŸ’¡ Future Improvements
ğŸ—‘ï¸ Expand to multi-class waste detection (Glass, Metal, Paper, E-waste)

ğŸ“± Export to TensorFlow Lite for mobile and IoT devices

ğŸŒˆ Add side-by-side Grad-CAM comparison view

ğŸš€ Integrate real-time camera feed for live classification

ğŸ“ˆ Results Snapshot
Metric	Value
Train Accuracy	93.5%
Validation Accuracy	93.0%
Test Accuracy	91.8%
Loss	0.21
F1-Score (avg)	0.92

ğŸ§­ Purpose
This project supports the Sustainable Development Goals (SDG 12: Responsible Consumption and Production) by enabling automated and transparent waste segregation â€” a crucial step toward smarter, cleaner cities.

ğŸ§‘â€ğŸ’» Author
Mayank Bhatt